{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hierarchical_LSTM_SuicideIntentIIITD_AmitAgarwal.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOa7UmYF7PxVa7tDO3mZMY5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amitagarwal2208/Suicide-Intent-Classification/blob/main/Hierarchical_LSTM_SuicideIntentIIITD_AmitAgarwal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBS3wqaDmsmO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer,  text_to_word_sequence\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers as initializers, regularizers, constraints\n",
        "from keras.callbacks import Callback, ModelCheckpoint\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding, Input, Dense, LSTM, GRU, Bidirectional, TimeDistributed, Dropout\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "from keras.models import Model\n",
        "import nltk\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from nltk import tokenize\n",
        "import seaborn as sns"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXbwmSBem0Hd",
        "outputId": "6c22d322-694b-46a6-8773-130dee50f2e3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iSnIcKCpmtsu"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/AmanuelF/Suicide-Risk-Assessment-using-Reddit/master/anonymized_dataset/500_Reddit_users_posts_labels.csv'\n",
        "df = pd.read_csv(url)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ubsw1n-vmwY_"
      },
      "source": [
        "df = df.dropna()\n",
        "X=df.drop('Label',axis=1)\n",
        "Y=df['Label']"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NVtHzvBtmyY2"
      },
      "source": [
        "messages = X.copy()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P74sjk1tm2VF"
      },
      "source": [
        "messages = []\n",
        "exclude = ['[',']',',',', ']\n",
        "\n",
        "for i in range(500):\n",
        "  l = df['Post'][i].split(\"'\") \n",
        "  l2 = []\n",
        "  for s in l:\n",
        "    if s not in exclude:\n",
        "      l2.append(s)\n",
        "\n",
        "  messages.append(l2)"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXhcmdTSm4VR"
      },
      "source": [
        "### Dataset Preprocessing\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "ps = PorterStemmer()\n",
        "corpus = []\n",
        "\n",
        "for i in range(500):\n",
        "  l = []\n",
        "  for text in messages[i]:\n",
        "    review = re.sub('[^a-zA-Z]', ' ', text)\n",
        "    review = review.lower()\n",
        "    review = review.split()\n",
        "    \n",
        "    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
        "    review = ' '.join(review)\n",
        "    l.append(review)\n",
        "\n",
        "  corpus.append(l) "
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV8xZ0dMm6FU"
      },
      "source": [
        "def get_max_sentences(corpus):\n",
        "\n",
        "  maxlen = 0 \n",
        "  for i in range(len(corpus)):\n",
        "    maxlen = max(maxlen,len(corpus[i]))\n",
        "\n",
        "  return maxlen\n",
        "\n",
        "def get_max_words(corpus):\n",
        "  maxwords = 0 \n",
        "\n",
        "  for i in range(len(corpus)):\n",
        "    for j in range(len(corpus[i])):\n",
        "      l = corpus[i][j].split(\" \")\n",
        "      maxwords = max(maxwords,len(l))\n",
        "\n",
        "  return maxwords\n",
        "\n",
        "\n",
        "def get_total_words(corpus):\n",
        "  total=0\n",
        "  for i in range(len(corpus)):\n",
        "    for j in range(len(corpus[i])):\n",
        "      l = corpus[i][j].split(\" \")\n",
        "      total+=len(l)\n",
        "\n",
        "  return total"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nek3BotNnKBW"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from keras.layers import Embedding\n",
        "from keras.layers import Dense, Input, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer, InputSpec\n"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j1jhOG8knmmZ",
        "outputId": "490961d5-5e49-4601-e522-3e3574d249f3"
      },
      "source": [
        "total_words = get_total_words(corpus)\n",
        "tokenizer = Tokenizer(nb_words=total_words)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5B5h_GxCnpf4"
      },
      "source": [
        "max_num_sentences = get_max_sentences(corpus)\n",
        "max_num_words = get_max_words(corpus)\n",
        "\n"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHO3v5D2s8It"
      },
      "source": [
        "X1 = np.zeros((len(corpus),max_num_sentences,max_num_words))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zi4dmYr2tLHi"
      },
      "source": [
        "def get_embeddings(corpus):\n",
        "\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  for i in range(len(corpus)):\n",
        "    sequences = tokenizer.texts_to_sequences(corpus[i])\n",
        "    sequences = np.array(sequences)\n",
        "    data = pad_sequences(sequences, maxlen=max_num_words)\n",
        "    \n",
        "    for j in range(data.shape[0]):\n",
        "      X1[i,j] = data[j]\n"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR3-63MQuHIw",
        "outputId": "2e52cfae-fdc9-41b3-99d0-90048c3f5ec6"
      },
      "source": [
        "get_embeddings(corpus)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6vO5Wkz2MZ1",
        "outputId": "61ac065d-524e-4785-a71f-e90c0224d7ed"
      },
      "source": [
        "X1[19]"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0.,    0.,    0., ...,    0.,    0.,   12.],\n",
              "       [   0.,    0.,    0., ..., 7560., 4687., 7560.],\n",
              "       [   0.,    0.,    0., ..., 4165., 7128.,    9.],\n",
              "       ...,\n",
              "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
              "       [   0.,    0.,    0., ...,    0.,    0.,    0.],\n",
              "       [   0.,    0.,    0., ...,    0.,    0.,    0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAyxA-sKuuyx"
      },
      "source": [
        "Y1 = np.zeros((len(corpus),max_num_sentences,5))\n",
        "\n",
        "for i in range(len(corpus)):\n",
        "  idx = -1\n",
        "  if Y[i] == 'Attempt':\n",
        "    idx = 0\n",
        "  elif Y[i] == 'Behavior':\n",
        "    idx = 1\n",
        "  elif Y[i] == 'Ideation':\n",
        "    idx = 2\n",
        "  elif Y[i] == 'Indicator':\n",
        "    idx = 3\n",
        "  elif Y[i] == 'Supportive':\n",
        "    idx = 4\n",
        "\n",
        "  for j in range(max_num_sentences):\n",
        "    Y1[i,j,idx] = 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcdm2Xudu7ok"
      },
      "source": [
        "X_train = X1[:375,:,:]\n",
        "X_test = X1[375:,:,:]\n",
        "Y_train = Y1[:375,:,:]\n",
        "Y_test = Y1[375:,:,:]"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqLNPtVbvdDJ",
        "outputId": "abd7c50b-3db8-40be-84f6-3d7d1dffe49c"
      },
      "source": [
        "sent_input = Input(shape=(max_num_sentences, max_num_words), dtype='float32')\n",
        "sent_lstm = (LSTM(150, return_sequences=True, kernel_regularizer=\"l2\"))(sent_input)\n",
        "sent_dense = TimeDistributed(Dense(200, kernel_regularizer=\"l2\"))(sent_lstm)\n",
        "print(sent_dense.shape)\n",
        "sentEncoder = Model(sent_input, sent_dense)\n",
        "\n",
        "\n",
        "user_input = Input(shape=(max_num_sentences,max_num_words), dtype='float32')\n",
        "print(user_input.shape)\n",
        "\n",
        "\n",
        "\n",
        "user_lstm = (LSTM(150, return_sequences=True, kernel_regularizer=\"l2\"))(user_input)\n",
        "user_dense = TimeDistributed(Dense(200, kernel_regularizer=\"l2\"))(user_lstm)\n",
        "print(user_dense.shape)\n",
        "preds = Dense(5, activation='softmax')(user_dense)\n",
        "#print(preds.shape)\n",
        "model = Model(user_input, preds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['acc'])"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 292, 200)\n",
            "(None, 292, 804)\n",
            "(None, 292, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBr8pA5KwPh-",
        "outputId": "9be5c2d8-f6e1-48ee-d008-016b55172de7"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(375, 292, 804)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzABN1KVxUQC",
        "outputId": "abda3cd1-13a8-4649-c53c-d1f192f63167"
      },
      "source": [
        "Y_train.shape"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(375, 292, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-B8qITcxvdk"
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3THOPSuxfF-",
        "outputId": "942f51ec-6946-4ae0-8503-4817a2b80557"
      },
      "source": [
        "model.fit(X_train, Y_train, validation_data=(X_test, Y_test),epochs=20, batch_size=10)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "38/38 [==============================] - 7s 174ms/step - loss: 1.5315 - acc: 0.3488 - val_loss: 1.5303 - val_acc: 0.3200\n",
            "Epoch 2/20\n",
            "38/38 [==============================] - 6s 170ms/step - loss: 1.5312 - acc: 0.3482 - val_loss: 1.5326 - val_acc: 0.3141\n",
            "Epoch 3/20\n",
            "38/38 [==============================] - 7s 173ms/step - loss: 1.5308 - acc: 0.3453 - val_loss: 1.5328 - val_acc: 0.3099\n",
            "Epoch 4/20\n",
            "38/38 [==============================] - 7s 174ms/step - loss: 1.5301 - acc: 0.3486 - val_loss: 1.5290 - val_acc: 0.3172\n",
            "Epoch 5/20\n",
            "38/38 [==============================] - 7s 180ms/step - loss: 1.5296 - acc: 0.3489 - val_loss: 1.5294 - val_acc: 0.3197\n",
            "Epoch 6/20\n",
            "38/38 [==============================] - 7s 180ms/step - loss: 1.5277 - acc: 0.3484 - val_loss: 1.5317 - val_acc: 0.3132\n",
            "Epoch 7/20\n",
            "38/38 [==============================] - 7s 183ms/step - loss: 1.5303 - acc: 0.3484 - val_loss: 1.5306 - val_acc: 0.3134\n",
            "Epoch 8/20\n",
            "38/38 [==============================] - 7s 181ms/step - loss: 1.5285 - acc: 0.3494 - val_loss: 1.5297 - val_acc: 0.3201\n",
            "Epoch 9/20\n",
            "38/38 [==============================] - 7s 178ms/step - loss: 1.5294 - acc: 0.3476 - val_loss: 1.5270 - val_acc: 0.3186\n",
            "Epoch 10/20\n",
            "38/38 [==============================] - 7s 177ms/step - loss: 1.5288 - acc: 0.3487 - val_loss: 1.5295 - val_acc: 0.3154\n",
            "Epoch 11/20\n",
            "38/38 [==============================] - 7s 173ms/step - loss: 1.5310 - acc: 0.3474 - val_loss: 1.5308 - val_acc: 0.3140\n",
            "Epoch 12/20\n",
            "38/38 [==============================] - 7s 173ms/step - loss: 1.5311 - acc: 0.3468 - val_loss: 1.5310 - val_acc: 0.3173\n",
            "Epoch 13/20\n",
            "38/38 [==============================] - 7s 172ms/step - loss: 1.5290 - acc: 0.3465 - val_loss: 1.5277 - val_acc: 0.3177\n",
            "Epoch 14/20\n",
            "38/38 [==============================] - 7s 173ms/step - loss: 1.5301 - acc: 0.3483 - val_loss: 1.5248 - val_acc: 0.3200\n",
            "Epoch 15/20\n",
            "38/38 [==============================] - 6s 172ms/step - loss: 1.5285 - acc: 0.3497 - val_loss: 1.5274 - val_acc: 0.3200\n",
            "Epoch 16/20\n",
            "38/38 [==============================] - 7s 174ms/step - loss: 1.5293 - acc: 0.3471 - val_loss: 1.5257 - val_acc: 0.3200\n",
            "Epoch 17/20\n",
            "38/38 [==============================] - 7s 179ms/step - loss: 1.5314 - acc: 0.3465 - val_loss: 1.5279 - val_acc: 0.3175\n",
            "Epoch 18/20\n",
            "38/38 [==============================] - 7s 185ms/step - loss: 1.5294 - acc: 0.3488 - val_loss: 1.5269 - val_acc: 0.3200\n",
            "Epoch 19/20\n",
            "38/38 [==============================] - 7s 185ms/step - loss: 1.5281 - acc: 0.3473 - val_loss: 1.5309 - val_acc: 0.3200\n",
            "Epoch 20/20\n",
            "38/38 [==============================] - 7s 187ms/step - loss: 1.5299 - acc: 0.3489 - val_loss: 1.5287 - val_acc: 0.3200\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72c6300050>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36iY4jEzDuHv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}